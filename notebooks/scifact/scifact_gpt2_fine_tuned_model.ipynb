{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiq29_d1TZjb",
    "outputId": "a9b70773-295d-4cab-ee5c-37b3b6688cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  3 04:41:10 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   70C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI7ffWYBTqrh",
    "outputId": "59061b4f-8a22-435a-d6d0-26667495654c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 54.8 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print('To enable a high-RAM runtime, select the Runtime â†’ \"Change runtime type\" ')\n",
    "    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "    print('re-execute this cell.')\n",
    "else:\n",
    "    print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axOb5sIQT67o",
    "outputId": "87e79b99-32b2-44bd-8622-1a22eef55ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 15101 MiB free out of 15360 MiB total\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory():\n",
    "    try:\n",
    "        # Run nvidia-smi and capture the output\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.free,memory.total', '--format=csv,nounits,noheader'],\n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(\"Failed to run nvidia-smi. Is NVIDIA driver installed?\")\n",
    "            print(result.stderr)\n",
    "            return\n",
    "\n",
    "        # Parse the output\n",
    "        memory_info = result.stdout.strip().split('\\n')\n",
    "        for i, gpu in enumerate(memory_info):\n",
    "            free, total = map(int, gpu.split(','))\n",
    "            print(f\"GPU {i}: {free} MiB free out of {total} MiB total\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi command not found. Make sure NVIDIA drivers are installed and the PATH is set.\")\n",
    "\n",
    "# Run the function\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZoSbw1vJp45",
    "outputId": "e66fb35c-7491-4187-8604-91a375df52c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQO3ksDLqJUk",
    "outputId": "5fd8d286-f6db-4009-865e-ea129ed102f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4mQWygJJ1hQ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Paths to data files\n",
    "training_data_path = \"/content/drive/MyDrive/646Project/scifact/training_data.jsonl\"\n",
    "eval_data_path = \"/content/drive/MyDrive/646Project/scifact/evaluation_data.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqjZdpO5JZ8o",
    "outputId": "764a2001-d458-4cec-f6fe-b390fafa84f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"gpt2\"  # Or any other GPT-2 variant\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n",
    "\n",
    "# Prepare the training data\n",
    "def prepare_train_data(training_data_path):\n",
    "    \"\"\"\n",
    "    Prepares the training data by combining query and positive text with EOS token.\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    with open(training_data_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line.strip())\n",
    "            # combined_text = f\"{example['query']} {tokenizer.eos_token} {example['positive_text']}\"\n",
    "            combined_text = f\"Generate a relevant pseudo-question for: {example['query']} {tokenizer.eos_token} {example['positive_text']}\"\n",
    "            train_data.append({\"text\": combined_text})\n",
    "    return train_data\n",
    "\n",
    "# Load and process the training dataset\n",
    "train_data = prepare_train_data(training_data_path)\n",
    "train_dataset = Dataset.from_list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbQMKYmQJdT1"
   },
   "outputs": [],
   "source": [
    "# Step 2: Prepare the Evaluation Dataset\n",
    "def prepare_eval_data(eval_data_path):\n",
    "    \"\"\"\n",
    "    Prepare the evaluation dataset for GPT-2 fine-tuning.\n",
    "    Concatenate an instruction, query, and text as input for causal language modeling.\n",
    "    \"\"\"\n",
    "    eval_data = []\n",
    "    with open(eval_data_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line.strip())\n",
    "            # Add the instructional prompt for consistency with training data\n",
    "            combined_text = f\"Generate a relevant pseudo-question for: {example['query']} {tokenizer.eos_token} {example['text']}\"\n",
    "            eval_data.append({\"text\": combined_text})\n",
    "    return eval_data\n",
    "\n",
    "# Load and process the evaluation dataset\n",
    "eval_data = prepare_eval_data(eval_data_path)\n",
    "eval_dataset = Dataset.from_list(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "d055477c1ef6446a9f9c518627bac9e7",
      "dca8de4561794cfa986a60024eccf31c",
      "9d6d40804a5b4aa59d6ca1d171357ac4",
      "071c547a87d6432d9a01e6be8a3212e8",
      "997f92795cd8472c8c5544dfe5e9b7ab",
      "4823080bea56499b8d96ed33c259a380",
      "4595af5c2aa94977abe7d0d078320b56",
      "092163eaff6b41ed8dff36fc47bb3570",
      "da238734c78147c1872cbf5cda084a5e",
      "97008cd297c7475e9d8b64f5e0bb6195",
      "15e055e9cab54ea3b1b8592bcdd6174a",
      "5ce3069fca914488ae9b273f98dddb13",
      "5c9cb4681bb54623832a6f2ab3f75531",
      "cf26bb93378e4651a0d87e93be9b0a19",
      "12d093b5f1ce4ffcb447779b44eb5670",
      "307ddc2b2b6643f09fee151103dd3149",
      "de26889a7a88491c86d88ba026cbd29c",
      "cd6033c0329a47808a4b67219728a71d",
      "210f1a98cb484afe966a05326c7d57c4",
      "898b088c66cb4554ab9275db0d185d55",
      "a8f89c39d7724d5ea6932e4d9dd993f0",
      "2021b3debae3415ead15a46ee70e6d2a"
     ]
    },
    "id": "Afs-UV8VJNVP",
    "outputId": "12303f77-66d2-48ba-eca7-52105b572d7d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d055477c1ef6446a9f9c518627bac9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/906 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce3069fca914488ae9b273f98dddb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Load GPT-2 Model and Tokenizer\n",
    "model_name = \"gpt2\"  # You can use \"gpt2-medium\" or \"gpt2-large\" if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Step 4: Tokenize the Datasets\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Step 5: Define Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # Causal LM requires no masking\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "6zZInakCJWV4",
    "outputId": "e2f49d6c-e631-4839-d4ce-e213c374ac97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-10-37933bbe425e>:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 02:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Steps: 171\n",
      "Training Loss: 3.632921542340552\n",
      "Metrics: {'train_runtime': 151.7432, 'train_samples_per_second': 17.912, 'train_steps_per_second': 1.127, 'total_flos': 710191742976000.0, 'train_loss': 3.632921542340552, 'epoch': 3.0}\n",
      "Model fine-tuned and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Step 6: Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/646Project/scifact/results-gpt2\",  # Save results in Google Drive\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"/content/drive/MyDrive/646Project/scifact/logs-gpt2\",  # Save logs in Google Drive\n",
    "    logging_steps=100,\n",
    "    eval_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,  # Enable mixed precision for faster training\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Step 7: Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Step 8: Train the Model\n",
    "# Assuming `trainer` is the Trainer object\n",
    "training_output = trainer.train()\n",
    "\n",
    "# Access metrics\n",
    "print(f\"Global Steps: {training_output.global_step}\")\n",
    "print(f\"Training Loss: {training_output.training_loss}\")\n",
    "print(f\"Metrics: {training_output.metrics}\")\n",
    "\n",
    "# Step 9: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/646Project/scifact/gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/646Project/scifact/gpt2_finetuned\")\n",
    "\n",
    "print(\"Model fine-tuned and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "y7sccEyA0Rda",
    "outputId": "1d8368a9-dcd0-4226-e69f-63bcd6843754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 2.747037887573242\n",
      "eval_runtime: 10.4082\n",
      "eval_samples_per_second: 44.58\n",
      "eval_steps_per_second: 2.786\n",
      "epoch: 3.0\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation metrics\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwmury1VQs31",
    "outputId": "55d299e9-cfa1-41be-f0b7-3857078e782e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/100 questions...\n",
      "Question: ADAR1 binds to Dicer to cleave pre-miRNA.\n",
      "Cleaned Response: ADAR1 binds to Dicer to cleave pre-miRNA.  What is the role of TKM in regulating miR2 expression? Does it regulate microRNAs and proteins that are involved in RNA replication or transmission by NcRs (noncerebellar nuclei)? Are they targeted at signaling pathways implicated in gene regulation through regulatory functions such as transcriptional activation, translation initiation and cell differentiation ? How do diphtheria regulates host cells via its interaction with different genes on protein folding sites using two distinct classes [16] , 17 ? The study was conducted over 12 weeks from April 25th till October 2nd 2016 during which time we found out more about how many RNIs were regulated under both proteins . We used an interferon beta/II ligand inhibitor system based upon RDA2721B7L6A3E9DQGCTTYZHCD5CXF\n",
      "Processed 20/100 questions...\n",
      "Question: Albendazole is used to treat lymphatic filariasis.\n",
      "Cleaned Response: Albendazole is used to treat lymphatic filariasis.  What are the two major classes of immune cells?\n",
      " The type I and Type II subtypes differ in their use by patients with CD4+ T cell disease (TcCD).Â  Primary prevention strategies include chemotherapy, immunotherapy or combination therapy . Secondary preventive programs involve transplantation into recipients' primary care systems at high risk populations such as elderly individuals who have been exposed to cytomegalovirus infection since childhood , AIDS virus infections that cause acute myeloid leukemia/ leukaemia - MMLR's / Leukemia associated lung cancer viruses which occur frequently across generations after diagnosis [ 1 ]. In this study we examined whether tumorigenesis was induced during progression from noncancerous stem lineage based on early differentiation rather than metastases triggered upon normal development stage induction via retrograde mitosis under standard human adhesion molecule ligand expression protocols compared wnts derived solely using\n",
      "Processed 30/100 questions...\n",
      "Question: Articles published in open access format are more likely to be cited than traditional journals.\n",
      "Cleaned Response: Articles published in open access format are more likely to be cited than traditional journals.  What is the most common reason why authors cite articles from multiple sources? Which factors influence citations and which ones do not, based on what study design was used or when did they were included into an analysis of data (or abstracts)? Are there two main reasons that include systematic bias as well?: 1) The quality review process can make it difficult/difficult if one's paper does have flaws compared with other papers; 2). Many studies show some degree at least partially due diligence by editors before publication although this may vary according\n",
      "In our own laboratory we conducted three reviews , each reviewing 10 different scientific publications . Each reviewer reviewed ten distinct peer reviewers who had been interviewed priorÂ to publishing their findings [ ]. We found no significant differences between those reports produced using standard methods such Aspins et al'2 where only six outof 12 manuscripts examined involved any single author\n",
      "Processed 40/100 questions...\n",
      "Question: Basophils counteract disease development in patients with systemic lupus erythematosus (SLE).\n",
      "Cleaned Response: Basophils counteract disease development in patients with systemic lupus erythematosus (SLE).  What is the role of mesenchymal stem cells? Does this mechanism account, at least partially through its effect on innate immune system function and survival. We show that T cell activation during autoimmune diseases leads to early onset infection resulting from lesion formation by acute myeloid leukemia virus EMTs or CD4+ lymphocytes within primary tumors . The involvement has been linked not only to human leukaemia but also associated macrophages such as miR8a1/2 which are involved in both immunodeficiency defense mechanisms including neutropenia regulation , central nervous systems balance responses against infections via differentiation into monocyte microglial progeny using cytokines IL3Î² + TLPRÎ³ signaling pathways etc.? Our study provides evidence supporting two main findings concerning peripheral blood flow when inflammation occurs late stage i progression upon\n",
      "Processed 50/100 questions...\n",
      "Question: CX3CR1 on the Th2 cells promotes T cell survival\n",
      "Cleaned Response: CX3CR1 on the Th2 cells promotes T cell survival  Does this study demonstrate that tumor necrosis factor Î± (TNFÎ±) and IL4 play roles in immune response to tumour growth? This is an important question. Here, we examined whether CD8+CD9 regulates IFNÎ³ secretion by breast cancer metastatic leukoencephalopathy as well as its induction of myeloid leukemia or lymphoma progression via immunodominant activation resulting from interferon beta signaling pathways induced after infection with Bcl5a . The presence/absentance of antigen receptor specific antibodies against IBDI can induce both cytotoxic responses generated during proliferative infiltration into epithelial neoplasia such as monocytes , neutrophils etc., which are required at early stages thereof through NFATP mediated regulation using targeted cytokines following proliferation inhibition associated apoptosis ? We found no evidence supporting either HLA coding region G6\n",
      "Processed 60/100 questions...\n",
      "Question: Chenodeosycholic acid treatment increases whole-body energy expenditure.\n",
      "Cleaned Response: Chenodeosycholic acid treatment increases whole-body energy expenditure.  What is the role of calcium in cellular metabolism?\n",
      " The purpose of this study was to determine whether or not dietary supplementation with vitamin D3 (DAZ) reduces body weight and cardiovascular disease risk factors by decreasing endogenous serum cholesterol levels through direct inhibition of intracellular lipoprotein oxidation via proinflammatory cytokines such as IL4, TNFÎ± and IFNÎ³ . In addition to their roles in vascular diseases , these are central functions that play an important part in regulating lipid homeostasis after injury due mainly to oxidative stress caused primarily from microorganism development during aging (). Furthermore, they have been used therapeutically against cancer cells induced peroxisome proliferator cell death (), which results directly into metastatic tumors resulting in decreased tumor survival () .\" A total of 1213 patients were enrolled at MAMU between November 2005 and April 2006 who had received one\n",
      "Processed 70/100 questions...\n",
      "Question: Cytochrome c is released from the mitochondrial intermembrane space to cytosol during apoptosis.\n",
      "Cleaned Response: Cytochrome c is released from the mitochondrial intermembrane space to cytosol during apoptosis.  What type of cytoplasmic lipid synthesis does mitochondria have? Is there an isoform or intracellular form in myeloid tissue that facilitates cleavage and release into cell membranes by T cells after membrane injury, thereby reducing cellular loss caused by oxidative stress induced lytic leukocytokine depletion at both peroxynitrite levels (PXN) level and Nrf2 function through activation of ROS metabolism pathways ? The purpose of this study was to determine if phosphorylation via PYK3A4 decreases oxidized proton channels involved in oxidation along with subsequent uptake as well tau formation upregulated downstream due either LPSO/TNF complex II signaling pathway inhibition [27], p38 MAP kinase 1 receptor knockout mice lacking NADPH blockade on their expression systems are able use nit\n",
      "Processed 80/100 questions...\n",
      "Question: Downregulation and mislocalization of Scribble prevents cell transformation and mammary tumorigenesis.\n",
      "Cleaned Response: Downregulation and mislocalization of Scribble prevents cell transformation and mammary tumorigenesis.  What is the molecular basis of myeloid leukemia? Does it affect chromosome integrity or differentiation in human cancer cells by affecting DNA methylation during transcriptional regulation (CRT)? Are epigenetic modifications associated with regulatory responses to CRT that regulate gene expression, activation, cytoskeletal remodeling, genomic rearrangements, cytokine release/reactivity etc.? How does chromatin homology change upon exposure to environmental stressors such as radiation from nuclear weapons sites ? Is this complex system involved in maintaining genome stability through its role in multiple target genes within heterogeneous populations , where more than one host organism can be targeted against at once .\n",
      " - Tissue assembly consists mostly of small molecules derived mainly directly out into hexagonal structures called nucleic acid clusters; these are composed largely of oligonucleotides produced only after ionizing irradiation ().\n",
      "Processed 90/100 questions...\n",
      "Question: Female carriers of the Apolipoprotein E4 (APOE4) allele have increased risk for dementia.\n",
      "Cleaned Response: Female carriers of the Apolipoprotein E4 (APOE4) allele have increased risk for dementia.  What is an example from this study? Does APO2 protect against Alzheimer's disease in mice lacking TK1/Akt protein or does it confer protection to human cells by affecting their cell viability and function ? Are there any potential benefits that we could observe based on our data regarding mouse models with tRNA activation vs cellular differentiation, aging , senescence etc.? If so how do these effects differ between species when compared towards single mutant animals / tissues where many genes are involved such as Ntb proteins & NFkB receptors - which has been associated with longevity development since 1999 ! In summary what can be seen here was observed at both plaques generated after exposure to apoE3 genotyping : The effector complex activated myeloid precursor gene LPSG11 during oxidative stress induction induced apoptosis . Furthermore CD8\n",
      "Processed 100/100 questions...\n",
      "Question: Golli-deficient T-cells prefer to differentiate into an anergic phenotype in the adaptive immune response when there are increased levels of Ca2+ in the cytosol.\n",
      "Cleaned Response: Golli-deficient T-cells prefer to differentiate into an anergic phenotype in the adaptive immune response when there are increased levels of Ca2+ in the cytosol.  What is their role? Are they able, at least partially or not, to reduce inflammation by activating autophagy and triggering innate immunity responses such as NFÎºB activation that promote immunological differentiation ? Is this mechanism necessary because IL1Î²/IL6 induced autoimmune diseases with more severe inflammatory features than patients without chronic lymphocytic leukemia , J Immunopath Biochem 1996 ; 10 : 709 â€“ 9 . 12 Sisson M Lea R Knecht H Schleicher L Deutsch EM A mouse model identifies myeloid leukocytes lacking endogenous proteins from mice living on high environmental stressors like obesity - type 1 diabetes mellitus (HOMA) pathology The importanceof functional rolesin human cells have been debated since its early development through\n",
      "Responses saved to /content/drive/MyDrive/646Project/scifact/gpt2_responses_finetuned_format.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the fine-tuned GPT-2 model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/646Project/scifact/gpt2_finetuned\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Ensure that the pad token is correctly set for consistent behavior\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load the JSON file with queries\n",
    "input_file_path = \"/content/drive/MyDrive/646Project/scifact/query_text_to_pseudo_questions_test.json\"\n",
    "with open(input_file_path, \"r\") as f:\n",
    "    query_data = json.load(f)\n",
    "\n",
    "# Post-processing function to clean the response\n",
    "def post_process_response(query, response):\n",
    "    \"\"\"\n",
    "    Removes the input text or prompt prefix from the response if it is repeated.\n",
    "\n",
    "    :param query: The input query\n",
    "    :param response: The generated response\n",
    "    :return: Cleaned response\n",
    "    \"\"\"\n",
    "    # Remove the instruction prefix if present\n",
    "    prompt_prefix = \"Generate a relevant pseudo-question for:\"\n",
    "    if prompt_prefix in response:\n",
    "        response = response.replace(prompt_prefix, \"\").strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "# Generate responses using fine-tuning format\n",
    "def generate_response_with_controls(query):\n",
    "    \"\"\"\n",
    "    Generates a response using the fine-tuning input format with controlled parameters.\n",
    "\n",
    "    :param query: The input query\n",
    "    :return: Generated pseudo-question\n",
    "    \"\"\"\n",
    "    # Use the same format as fine-tuning\n",
    "    input_text = f\"Generate a relevant pseudo-question for: {query} {tokenizer.eos_token}\"\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    # Use sampling for more diverse and less repetitive responses\n",
    "    output_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=200,  # Adjust as needed\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,  # Enable sampling\n",
    "        temperature=0.7,  # Control randomness\n",
    "        top_p=0.9,  # Nucleus sampling for diversity\n",
    "        repetition_penalty=1.2,  # Penalize repeated tokens\n",
    "        num_return_sequences=1,  # Return one response per query\n",
    "    )\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Process the queries and generate responses\n",
    "responses = {}\n",
    "total_queries = len(query_data)\n",
    "\n",
    "for i, question in enumerate(query_data.keys(), start=1):\n",
    "    # Generate response\n",
    "    raw_response = generate_response_with_controls(question)\n",
    "    # Post-process response\n",
    "    cleaned_response = post_process_response(question, raw_response)\n",
    "    responses[question] = cleaned_response\n",
    "\n",
    "    # Print the question and response every 10 queries or at the end\n",
    "    if i % 10 == 0 or i == total_queries:\n",
    "        print(f\"Processed {i}/{total_queries} questions...\")\n",
    "        print(f\"Question: {question}\")\n",
    "        # print(f\"Raw Response: {raw_response}\")\n",
    "        print(f\"Cleaned Response: {cleaned_response}\")\n",
    "\n",
    "# Save the responses into a file\n",
    "output_file_path = \"/content/drive/MyDrive/646Project/scifact/gpt2_responses_finetuned_format.json\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(responses, f, indent=4)\n",
    "\n",
    "print(f\"Responses saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "referenced_widgets": [
      "deff31bce4a0481eba053a22ac92039d",
      "aab907276792458f8c075a1d71272421",
      "5250b7e148c64e63b95ee4a7cd9101e3",
      "800778ace4e94176ac5036b9b5819405",
      "278e270c07384d9e8a169bfb7ffd210c",
      "fd63de0bf8e94cc4bfac5bb329793642",
      "1b65a56e61a34b71a82bd827ae60601d",
      "c088dc687ce948468c85eaa71bcdae0a",
      "e166941204c44ed98029898da98f0046",
      "079400dedf90440fa85cac9a3d819fb7",
      "35d5d1457b9447af8d993c5bb7bb9d0e",
      "c8abb69ecece43039d5d588e6b1ece61",
      "1c88991c26244b48b5fba9c9da3edeca",
      "58812fcd22d245aa9283fb46232ae4d4",
      "f32c5cf5e97c4a19bba1dfca93efdb75",
      "f9b2687581d740ad87f0c24cf7bcb258",
      "edac981b1a8b42efabdbbfe83cbd9950",
      "bed71f689b9d4ab1bc3536c66f901d89",
      "407fe01e656f49bea5b7c381006bb159",
      "438e1b22157c4d9a9be9b261f0556f4a",
      "71e33a31cf6b43c5905f330c875f611e",
      "73a600a6e15c4dd5afd95fe2c0b644a5",
      "4498f4a5a30d46f1a36c8c0fca516f17",
      "a8785c4ec6e642efaa9b73554d5e1014",
      "34b62d5641724bd9a3a2363fd0d27f97",
      "dd52e265efd4457884f3a4b73ac321d1",
      "4fa9663c390841109b1a29564e0bda0c",
      "ccfb4a5a0695461ea782b195b298bf6f",
      "772ee3ea658a49d0a90bb4e160b8e714",
      "ca28805d85ca4b4ba88ba407be38cff4",
      "3d0606ff95ba41e5a225f502feafb178",
      "bf513c964a604b4f935b4182d9e90148",
      "814cd6f428e547938df04067a395c770",
      "b785706b73884cb69c9391f600cf29f8",
      "ba7cb60672fa4761b5aa548d6e82887f",
      "f50f666da44246aab1e310c12bb36020",
      "2663addc6959441097dc42656dd99374",
      "aaa5cd925b0d4bad8d114b3ea9c7c548",
      "40a1cbeb01164411bbd1d4bb21bfe5aa",
      "c99f03967f7e443ebbe10325cf0b0edc",
      "c50e856a07694b1b89e3b0028cdbe6d5",
      "fde4ed07912742a3b81082394002a3eb",
      "b41a7cf445bf4dbba31d083fa71f72b0",
      "92f75a413d574b31a0fc30f9c238fdfa"
     ]
    },
    "id": "7MSM9JPpVUx2",
    "outputId": "988442bd-c1b6-4924-f802-daf66d199385"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deff31bce4a0481eba053a22ac92039d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8abb69ecece43039d5d588e6b1ece61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scifact.py:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4498f4a5a30d46f1a36c8c0fca516f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "queries/queries/0000.parquet:   0%|          | 0.00/67.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b785706b73884cb69c9391f600cf29f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/1109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID-to-response mapping saved to /content/drive/MyDrive/646Project/scifact/gpt2_id_response_mapping.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the GPT-2 responses file\n",
    "responses_file_path = \"/content/drive/MyDrive/646Project/scifact/gpt2_responses_finetuned_format.json\"\n",
    "with open(responses_file_path, \"r\") as f:\n",
    "    eval_with_responses = json.load(f)  # Loaded as a dictionary\n",
    "\n",
    "# Load scifact dataset queries\n",
    "dataset_q = load_dataset(\"BeIR/scifact\", \"queries\")\n",
    "queries_dataset = dataset_q[\"queries\"]\n",
    "\n",
    "# Map questions to their IDs\n",
    "def map_questions_to_ids(eval_with_responses, queries_dataset):\n",
    "    \"\"\"\n",
    "    Maps the queries in eval_with_responses to their IDs in the queries_dataset.\n",
    "\n",
    "    :param eval_with_responses: Dictionary with query-response pairs\n",
    "    :param queries_dataset: HF dataset containing questions and their IDs\n",
    "    :return: Dictionary mapping question IDs to responses\n",
    "    \"\"\"\n",
    "    id_response_mapping = {}\n",
    "    for question, response in eval_with_responses.items():\n",
    "        # Find the matching question ID\n",
    "        question_id = None\n",
    "        for query in queries_dataset:\n",
    "            if query[\"text\"] == question:\n",
    "                question_id = query[\"_id\"]\n",
    "                break\n",
    "\n",
    "        if question_id is not None:\n",
    "            id_response_mapping[question_id] = response\n",
    "        else:\n",
    "            print(f\"ID not found for query: {question}\")\n",
    "\n",
    "    return id_response_mapping\n",
    "\n",
    "# Create the mapping\n",
    "id_response_mapping = map_questions_to_ids(eval_with_responses, queries_dataset)\n",
    "\n",
    "# Save the ID-to-response mapping to a file\n",
    "id_response_output_path = \"/content/drive/MyDrive/646Project/scifact/gpt2_id_response_mapping.json\"\n",
    "with open(id_response_output_path, \"w\") as f:\n",
    "    json.dump(id_response_mapping, f, indent=4)\n",
    "\n",
    "print(f\"ID-to-response mapping saved to {id_response_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7gtZAunlLVy",
    "outputId": "6d9c1dc3-d0c4-4186-8a17-36ea8e1054a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "# Install the OpenAI library if not already installed\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIZXwcdN6N3T"
   },
   "outputs": [],
   "source": [
    "mport json\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Fine-tuned model ID\n",
    "fine_tuned_model_id = \"ft:gpt-3.5-turbo-0125:personal:3rdattemptnfcorpus:AZVe3AnC\"\n",
    "\n",
    "# Retrieve fine-tuning job details\n",
    "fine_tune_job = openai.FineTune.retrieve(id=fine_tuned_model_id)\n",
    "# Print the details\n",
    "print(fine_tune_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72LOkyDff0uJ",
    "outputId": "43ea7402-7d22-4072-f578-72a8753ecd0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/100 questions...\n",
      "Question: ADAR1 binds to Dicer to cleave pre-miRNA.\n",
      "Response: Does the lack of a specific binding site on TGF-beta1 mRNA suggest that it is What are the two main types of diabetes that can be found in South Asians? Does the presence of antibodies to Campylobacter jejuni in patients with Guillain-Barre syndrome What is the relationship between mercury and sex hormones in male fish eaters? How does the human body recognize and respond to double-stranded RNA?\n",
      "Processed 20/100 questions...\n",
      "Question: Albendazole is used to treat lymphatic filariasis.\n",
      "Response: What is the purpose of this work? What is the dietary condition called when an individual has a deficiency in tryptophan? Which of the following is not a recognized use for ivermectin: control or elimination? Does the study suggest that more women should be informed about MHT and how it may affect their What is the purpose of this study?\n",
      "Processed 30/100 questions...\n",
      "Question: Articles published in open access format are more likely to be cited than traditional journals.\n",
      "Response: Are there any other potential mechanisms of curcumin's action against Alzheimer disease? What are the main findings of this study? Does the HIF-1 pathway play a role in cancer progression? What are the limitations of this study? What are the main findings of this paper?\n",
      "Processed 40/100 questions...\n",
      "Question: Basophils counteract disease development in patients with systemic lupus erythematosus (SLE).\n",
      "Response: What was the concentration of TGF-beta1 in patients with Crohn's disease? What are the two major reasons for the occurrence of food allergy and intolerance? Does the antibody to galactose-1-phosphate uridyltransferase bind What is the most recent update on the role of diet and nutrition in rheumatoid arthritis? Does the addition of 10 grams of cherries to the diet lower uric acid in healthy\n",
      "Processed 50/100 questions...\n",
      "Question: CX3CR1 on the Th2 cells promotes T cell survival\n",
      "Response: Does a study of the impact of fruit and vegetable consumption on markers of oxidative stress in adults What is the purpose of this study? What is the effect of n-hexane and methanol extracts of green or roasted coffee What is the cellular target of this research? What is the main problem with T cell interactions that are not mediated by antigen?\n",
      "Processed 60/100 questions...\n",
      "Question: Chenodeosycholic acid treatment increases whole-body energy expenditure.\n",
      "Response: Which of the following is a potential source of endocrine disruptors: pesticides, pharmaceuticals What are the major conclusions of this study? How do the authors of this article describe their findings? Does a high-protein diet increase urinary calcium loss in postmenopausal women? What is the purpose of this review?\n",
      "Processed 70/100 questions...\n",
      "Question: Cytochrome c is released from the mitochondrial intermembrane space to cytosol during apoptosis.\n",
      "Response: What are the two proteins involved in autophagy? What is the relationship between sex and age? What is the difference between chronic kidney disease and anemia? Does the study identify any possible risk factors for cancer? What is the main idea of this passage?\n",
      "Processed 80/100 questions...\n",
      "Question: Downregulation and mislocalization of Scribble prevents cell transformation and mammary tumorigenesis.\n",
      "Response: What is the relationship between disease and age? What are the results of this study? Do the findings of a previous study support the hypothesis that methionine restriction (MR) may be Does high fat diet modulate the growth of human prostate cancer in SCID mice? What does the author suggest about estrogen and progesterone hormone replacement therapy?\n",
      "Processed 90/100 questions...\n",
      "Question: Female carriers of the Apolipoprotein E4 (APOE4) allele have increased risk for dementia.\n",
      "Response: How is the Glycemic Index of a food determined? What is the main purpose of this study? Does the paper identify a single environmental factor as being most important for the development of testi What is the most common way of identifying and treating bipolar disorder? Does the consumption of n-3 PUFA reduce risk of major cardiovascular outcomes?\n",
      "Processed 100/100 questions...\n",
      "Question: Golli-deficient T-cells prefer to differentiate into an anergic phenotype in the adaptive immune response when there are increased levels of Ca2+ in the cytosol.\n",
      "Response: What is the role of calcium in the activation of T cells? What is the relationship between dietary fiber intake and the risk of breast cancer among women? What is the relationship between IL-10 and TGF-beta in human milk? What are the main findings of this article? Does a novel association between intestinal microbiota and obesity in humans?\n",
      "Responses saved to /content/drive/MyDrive/646Project/scifact/gpt3_multiple_responses_concatenated.json\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#                              GPT-3 CONTEXT                                   #\n",
    "################################################################################\n",
    "\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Set the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Load the JSON file with queries\n",
    "input_file_path = \"/content/drive/MyDrive/646Project/scifact/query_text_to_pseudo_questions_test.json\"\n",
    "with open(input_file_path, \"r\") as f:\n",
    "    query_data = json.load(f)\n",
    "\n",
    "\n",
    "# Define the system message guiding the model's behavior\n",
    "system_message = (\n",
    "    \"You are a helpful assistant that generates one relevant, novel, and contextually rich question about the given input. Only provide the resulting question.\"\n",
    ")\n",
    "\n",
    "# Function to generate a response using GPT-3.5-turbo\n",
    "def generate_response_with_gpt3(query_text):\n",
    "    \"\"\"\n",
    "    Generates a response using the fine-tuned GPT-3.5-turbo model.\n",
    "\n",
    "    :param query_text: The input query\n",
    "    :return: Generated pseudo-question\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Call the GPT-3.5 API with structured messages\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"ft:gpt-3.5-turbo-0125:personal:3rdattemptnfcorpus:AZVe3AnC\",  # Your fine-tuned model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate a new question about the question: '{query_text}'\"}\n",
    "            ],\n",
    "            max_tokens=200,  # Limit the length of the response\n",
    "            temperature=0.7,  # Control randomness\n",
    "            top_p=0.9,  # Nucleus sampling\n",
    "            frequency_penalty=1.2,  # Penalize repeated phrases\n",
    "            presence_penalty=0.6, # Encourage new topics\n",
    "        )\n",
    "        # Extract the assistant's message\n",
    "        generated_question = response.choices[0].message.content.strip()\n",
    "        return generated_question\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response for query '{query_text}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Process the queries and generate concatenated responses\n",
    "responses = {}\n",
    "total_queries = len(query_data)\n",
    "\n",
    "for i, question in enumerate(query_data.keys(), start=1):\n",
    "    concatenated_responses = []\n",
    "\n",
    "    for attempt in range(5):  # Ask the model 5 times\n",
    "        response = generate_response_with_gpt3(question)\n",
    "        if response:\n",
    "            concatenated_responses.append(response)\n",
    "\n",
    "    # Combine all 5 responses into a single sentence\n",
    "    if concatenated_responses:\n",
    "        combined_response = \" \".join(concatenated_responses)\n",
    "        responses[question] = combined_response\n",
    "\n",
    "    # Print progress every 10 queries or at the end\n",
    "    if i % 10 == 0 or i == total_queries:\n",
    "        print(f\"Processed {i}/{total_queries} questions...\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Response: {combined_response if concatenated_responses else 'No valid responses generated.'}\")\n",
    "\n",
    "# Save the responses into a file\n",
    "output_file_path = \"/content/drive/MyDrive/646Project/scifact/gpt3_multiple_responses_concatenated.json\"\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(responses, f, indent=4)\n",
    "\n",
    "print(f\"Responses saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PG12nHDQf16c",
    "outputId": "2f938055-0345-43c9-82fd-41658b01c26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID-to-response mapping saved to /content/drive/MyDrive/646Project/scifact/gpt3_multiple_id_response_mapping.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the GPT-3 multiple responses file\n",
    "responses_file_path = \"/content/drive/MyDrive/646Project/scifact/gpt3_multiple_responses_concatenated.json\"\n",
    "with open(responses_file_path, \"r\") as f:\n",
    "    eval_with_responses = json.load(f)  # Loaded as a dictionary with original queries as keys\n",
    "\n",
    "# Load scifact dataset queries\n",
    "dataset_q = load_dataset(\"BeIR/scifact\", \"queries\")\n",
    "queries_dataset = dataset_q[\"queries\"]\n",
    "\n",
    "# Map questions to their IDs\n",
    "def map_questions_to_ids(eval_with_responses, queries_dataset):\n",
    "    \"\"\"\n",
    "    Maps the queries in eval_with_responses to their IDs in the queries_dataset.\n",
    "\n",
    "    :param eval_with_responses: Dictionary with query-response pairs\n",
    "    :param queries_dataset: HF dataset containing questions and their IDs\n",
    "    :return: Dictionary mapping question IDs to concatenated responses\n",
    "    \"\"\"\n",
    "    id_response_mapping = {}\n",
    "    for question, concatenated_response in eval_with_responses.items():\n",
    "        # Find the matching question ID\n",
    "        question_id = None\n",
    "        for query in queries_dataset:\n",
    "            if query[\"text\"] == question:\n",
    "                question_id = query[\"_id\"]\n",
    "                break\n",
    "\n",
    "        if question_id is not None:\n",
    "            id_response_mapping[question_id] = concatenated_response\n",
    "        else:\n",
    "            print(f\"ID not found for query: {question}\")\n",
    "\n",
    "    return id_response_mapping\n",
    "\n",
    "# Create the mapping from question IDs to concatenated responses\n",
    "id_response_mapping = map_questions_to_ids(eval_with_responses, queries_dataset)\n",
    "\n",
    "# Save the ID-to-response mapping to a file\n",
    "id_response_output_path = \"/content/drive/MyDrive/646Project/scifact/gpt3_multiple_id_response_mapping.json\"\n",
    "with open(id_response_output_path, \"w\") as f:\n",
    "    json.dump(id_response_mapping, f, indent=4)\n",
    "\n",
    "print(f\"ID-to-response mapping saved to {id_response_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "071c547a87d6432d9a01e6be8a3212e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97008cd297c7475e9d8b64f5e0bb6195",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_15e055e9cab54ea3b1b8592bcdd6174a",
      "value": "â€‡906/906â€‡[00:00&lt;00:00,â€‡2532.45â€‡examples/s]"
     }
    },
    "079400dedf90440fa85cac9a3d819fb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "092163eaff6b41ed8dff36fc47bb3570": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d093b5f1ce4ffcb447779b44eb5670": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8f89c39d7724d5ea6932e4d9dd993f0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2021b3debae3415ead15a46ee70e6d2a",
      "value": "â€‡464/464â€‡[00:00&lt;00:00,â€‡3654.44â€‡examples/s]"
     }
    },
    "15e055e9cab54ea3b1b8592bcdd6174a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b65a56e61a34b71a82bd827ae60601d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c88991c26244b48b5fba9c9da3edeca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edac981b1a8b42efabdbbfe83cbd9950",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bed71f689b9d4ab1bc3536c66f901d89",
      "value": "scifact.py:â€‡100%"
     }
    },
    "2021b3debae3415ead15a46ee70e6d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "210f1a98cb484afe966a05326c7d57c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2663addc6959441097dc42656dd99374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b41a7cf445bf4dbba31d083fa71f72b0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_92f75a413d574b31a0fc30f9c238fdfa",
      "value": "â€‡1109/1109â€‡[00:00&lt;00:00,â€‡30989.43â€‡examples/s]"
     }
    },
    "278e270c07384d9e8a169bfb7ffd210c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307ddc2b2b6643f09fee151103dd3149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34b62d5641724bd9a3a2363fd0d27f97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca28805d85ca4b4ba88ba407be38cff4",
      "max": 67476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d0606ff95ba41e5a225f502feafb178",
      "value": 67476
     }
    },
    "35d5d1457b9447af8d993c5bb7bb9d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d0606ff95ba41e5a225f502feafb178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "407fe01e656f49bea5b7c381006bb159": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40a1cbeb01164411bbd1d4bb21bfe5aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438e1b22157c4d9a9be9b261f0556f4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4498f4a5a30d46f1a36c8c0fca516f17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8785c4ec6e642efaa9b73554d5e1014",
       "IPY_MODEL_34b62d5641724bd9a3a2363fd0d27f97",
       "IPY_MODEL_dd52e265efd4457884f3a4b73ac321d1"
      ],
      "layout": "IPY_MODEL_4fa9663c390841109b1a29564e0bda0c"
     }
    },
    "4595af5c2aa94977abe7d0d078320b56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4823080bea56499b8d96ed33c259a380": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa9663c390841109b1a29564e0bda0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5250b7e148c64e63b95ee4a7cd9101e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c088dc687ce948468c85eaa71bcdae0a",
      "max": 13995,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e166941204c44ed98029898da98f0046",
      "value": 13995
     }
    },
    "58812fcd22d245aa9283fb46232ae4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407fe01e656f49bea5b7c381006bb159",
      "max": 1656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_438e1b22157c4d9a9be9b261f0556f4a",
      "value": 1656
     }
    },
    "5c9cb4681bb54623832a6f2ab3f75531": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de26889a7a88491c86d88ba026cbd29c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd6033c0329a47808a4b67219728a71d",
      "value": "Map:â€‡100%"
     }
    },
    "5ce3069fca914488ae9b273f98dddb13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c9cb4681bb54623832a6f2ab3f75531",
       "IPY_MODEL_cf26bb93378e4651a0d87e93be9b0a19",
       "IPY_MODEL_12d093b5f1ce4ffcb447779b44eb5670"
      ],
      "layout": "IPY_MODEL_307ddc2b2b6643f09fee151103dd3149"
     }
    },
    "71e33a31cf6b43c5905f330c875f611e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73a600a6e15c4dd5afd95fe2c0b644a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "772ee3ea658a49d0a90bb4e160b8e714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "800778ace4e94176ac5036b9b5819405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_079400dedf90440fa85cac9a3d819fb7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_35d5d1457b9447af8d993c5bb7bb9d0e",
      "value": "â€‡14.0k/14.0kâ€‡[00:00&lt;00:00,â€‡1.04MB/s]"
     }
    },
    "814cd6f428e547938df04067a395c770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "898b088c66cb4554ab9275db0d185d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92f75a413d574b31a0fc30f9c238fdfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97008cd297c7475e9d8b64f5e0bb6195": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997f92795cd8472c8c5544dfe5e9b7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d6d40804a5b4aa59d6ca1d171357ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_092163eaff6b41ed8dff36fc47bb3570",
      "max": 906,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da238734c78147c1872cbf5cda084a5e",
      "value": 906
     }
    },
    "a8785c4ec6e642efaa9b73554d5e1014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccfb4a5a0695461ea782b195b298bf6f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_772ee3ea658a49d0a90bb4e160b8e714",
      "value": "queries/queries/0000.parquet:â€‡100%"
     }
    },
    "a8f89c39d7724d5ea6932e4d9dd993f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaa5cd925b0d4bad8d114b3ea9c7c548": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aab907276792458f8c075a1d71272421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd63de0bf8e94cc4bfac5bb329793642",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1b65a56e61a34b71a82bd827ae60601d",
      "value": "README.md:â€‡100%"
     }
    },
    "b41a7cf445bf4dbba31d083fa71f72b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b785706b73884cb69c9391f600cf29f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba7cb60672fa4761b5aa548d6e82887f",
       "IPY_MODEL_f50f666da44246aab1e310c12bb36020",
       "IPY_MODEL_2663addc6959441097dc42656dd99374"
      ],
      "layout": "IPY_MODEL_aaa5cd925b0d4bad8d114b3ea9c7c548"
     }
    },
    "ba7cb60672fa4761b5aa548d6e82887f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40a1cbeb01164411bbd1d4bb21bfe5aa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c99f03967f7e443ebbe10325cf0b0edc",
      "value": "Generatingâ€‡queriesâ€‡split:â€‡100%"
     }
    },
    "bed71f689b9d4ab1bc3536c66f901d89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf513c964a604b4f935b4182d9e90148": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c088dc687ce948468c85eaa71bcdae0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c50e856a07694b1b89e3b0028cdbe6d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8abb69ecece43039d5d588e6b1ece61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c88991c26244b48b5fba9c9da3edeca",
       "IPY_MODEL_58812fcd22d245aa9283fb46232ae4d4",
       "IPY_MODEL_f32c5cf5e97c4a19bba1dfca93efdb75"
      ],
      "layout": "IPY_MODEL_f9b2687581d740ad87f0c24cf7bcb258"
     }
    },
    "c99f03967f7e443ebbe10325cf0b0edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca28805d85ca4b4ba88ba407be38cff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfb4a5a0695461ea782b195b298bf6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6033c0329a47808a4b67219728a71d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf26bb93378e4651a0d87e93be9b0a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_210f1a98cb484afe966a05326c7d57c4",
      "max": 464,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_898b088c66cb4554ab9275db0d185d55",
      "value": 464
     }
    },
    "d055477c1ef6446a9f9c518627bac9e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dca8de4561794cfa986a60024eccf31c",
       "IPY_MODEL_9d6d40804a5b4aa59d6ca1d171357ac4",
       "IPY_MODEL_071c547a87d6432d9a01e6be8a3212e8"
      ],
      "layout": "IPY_MODEL_997f92795cd8472c8c5544dfe5e9b7ab"
     }
    },
    "da238734c78147c1872cbf5cda084a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dca8de4561794cfa986a60024eccf31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4823080bea56499b8d96ed33c259a380",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4595af5c2aa94977abe7d0d078320b56",
      "value": "Map:â€‡100%"
     }
    },
    "dd52e265efd4457884f3a4b73ac321d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf513c964a604b4f935b4182d9e90148",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_814cd6f428e547938df04067a395c770",
      "value": "â€‡67.5k/67.5kâ€‡[00:00&lt;00:00,â€‡4.83MB/s]"
     }
    },
    "de26889a7a88491c86d88ba026cbd29c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deff31bce4a0481eba053a22ac92039d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aab907276792458f8c075a1d71272421",
       "IPY_MODEL_5250b7e148c64e63b95ee4a7cd9101e3",
       "IPY_MODEL_800778ace4e94176ac5036b9b5819405"
      ],
      "layout": "IPY_MODEL_278e270c07384d9e8a169bfb7ffd210c"
     }
    },
    "e166941204c44ed98029898da98f0046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "edac981b1a8b42efabdbbfe83cbd9950": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f32c5cf5e97c4a19bba1dfca93efdb75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71e33a31cf6b43c5905f330c875f611e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_73a600a6e15c4dd5afd95fe2c0b644a5",
      "value": "â€‡1.66k/1.66kâ€‡[00:00&lt;00:00,â€‡131kB/s]"
     }
    },
    "f50f666da44246aab1e310c12bb36020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c50e856a07694b1b89e3b0028cdbe6d5",
      "max": 1109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fde4ed07912742a3b81082394002a3eb",
      "value": 1109
     }
    },
    "f9b2687581d740ad87f0c24cf7bcb258": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd63de0bf8e94cc4bfac5bb329793642": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fde4ed07912742a3b81082394002a3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
